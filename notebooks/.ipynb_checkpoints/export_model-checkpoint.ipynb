{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN - Inspect Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the work of Waleed Abdulla (Matterport)\n",
    "Modified by github.com/GustavZ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "# Model  Directory \n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_WEIGHTS = os.path.join(ROOT_DIR, \"mask_rcnn_drug_mobile.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS COCO Dataset\n",
    "import multiprocessing\n",
    "\n",
    "import train_coco\n",
    "config = train_coco.TrainConfig(\"drug\", 512, 1, 1)\n",
    "COCO_DIR = os.path.join(ROOT_DIR,\"data/coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       mobilenetv1\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           drug\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_MULTIPROCESSING            True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    IMAGES_PER_GPU = 1\n",
    "    BACKBONE = \"mobilenetv1\"\n",
    "\n",
    "config = InferenceConfig(\"drug\", 512, 1, 1)\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"\n",
    "# DEVICE = \"/gpu:0\"\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "#TEST_MODE = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path to trained h5 weights file\n",
    "MODEL_NAME = 'mask_rcnn_mobileconvert' # TODO: enter value here\n",
    "H5_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+\".h5\") # TODO: enter value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0221 11:20:44.043414 4461974976 deprecation_wrapper.py:119] From /Users/apple/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0221 11:20:44.425672 4461974976 deprecation_wrapper.py:119] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:689: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0221 11:20:44.433605 4461974976 deprecation.py:323] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:747: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0221 11:20:44.439567 4461974976 deprecation.py:506] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:771: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0221 11:20:44.647777 4461974976 deprecation_wrapper.py:119] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:1070: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "W0221 11:20:44.651283 4461974976 deprecation_wrapper.py:119] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:1072: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "W0221 11:20:44.728718 4461974976 deprecation.py:323] From /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mrcnn/model.py:1122: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/mask_rcnn_drug_mobile.h5\n"
     ]
    }
   ],
   "source": [
    "import mrcnn.model as modellib\n",
    "\n",
    "# Create model in inference mode\n",
    "\n",
    "model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "# Set path to model weights\n",
    "weights_path = DEFAULT_WEIGHTS\n",
    "#weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the pb file we want to output\n",
    "MODEL_NAME = 'mask_rcnn_drug_mobile' # TODO: enter value here\n",
    "\n",
    "# Chose whether to quantize the graph\n",
    "QUANTIZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 11:20:52.733520 4461974976 deprecation.py:323] From <ipython-input-9-a23445de2108>:26: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0221 11:20:52.734327 4461974976 deprecation.py:323] From /Users/apple/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "# Get keras model and save\n",
    "model_keras= model.keras_model\n",
    "# All new operations will be in test mode from now on.\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Create output layer with customized names\n",
    "num_output = 7\n",
    "pred_node_names = [\"detections\", \"mrcnn_class\", \"mrcnn_bbox\", \"mrcnn_mask\", \"rois\", \"rpn_class\", \"rpn_bbox\"]\n",
    "pred_node_names = [\"output_\" + name for name in pred_node_names]\n",
    "pred = [tf.identity(model_keras.outputs[i], name = pred_node_names[i])for i in range(num_output)]\n",
    "\n",
    "# Get the object detection graph\n",
    "sess = K.get_session()\n",
    "if QUANTIZE:\n",
    "    # Transformations\n",
    "    transforms = [\"quantize_weights\", \"quantize_nodes\"]\n",
    "    transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [], pred_node_names, transforms)\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, transformed_graph_def, pred_node_names)\n",
    "    PB_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+'.pb') \n",
    "else:\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "    PB_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+'_quantized'+'.pb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705 ops in the frozen graph.\n",
      "saved the freezed graph (ready for inference) at:  /Users/apple/Desktop/machine_learning/projects/Mobile_Mask_RCNN/logs/mask_rcnn_drug_mobile_quantized.pb\n"
     ]
    }
   ],
   "source": [
    "# Write Output pb File\n",
    "graph_io.write_graph(constant_graph, \"/\", PB_MODEL_PATH, as_text=False)\n",
    "\n",
    "# Output Info\n",
    "print('{} ops in the frozen graph.'.format(len(constant_graph.node)))\n",
    "print('saved the freezed graph (ready for inference) at: ', PB_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model\n",
    "Now, we can load the model from the pb file and then use it to infere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES NOT WORK YET\n",
    "\n",
    "import cv2 \n",
    "from mrcnn import utils\n",
    "from mrcnn.model import compose_image_meta\n",
    "\n",
    "utils.set_cuda_visible_devices(config.GPU_COUNT)\n",
    "with tf.device(DEVICE):\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        output_graph_def = tf.GraphDef()\n",
    "        with open(PB_MODEL_PATH, \"rb\") as f:\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "\n",
    "        image = cv2.imread(ROOT_DIR+\"/05_test.jpg\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.resize(image,(config.IMAGE_MAX_DIM,config.IMAGE_MAX_DIM), interpolation=cv2.INTER_CUBIC)\n",
    "        # image = np.expand_dims(image,0)\n",
    "\n",
    "        image_resized, window, scale, padding, _ = utils.resize_image(image,  min_dim=config.IMAGE_MIN_DIM, max_dim=config.IMAGE_MAX_DIM,mode=config.IMAGE_RESIZE_MODE    )\n",
    "        image_meta = compose_image_meta(image_id=1, original_image_shape=image_resized, image_shape=image_resized.shape, window=window,scale=scale, active_class_ids=[0,1])\n",
    "        image_meta = np.expand_dims(image_meta,0)\n",
    "        image_resized = np.expand_dims(image_resized, 0)\n",
    "        graph = tf.get_default_graph()\n",
    "        input_image = graph.get_tensor_by_name(\"input_image:0\")\n",
    "        input_image_meta = graph.get_tensor_by_name(\"input_image_meta:0\")\n",
    "        mrcnn_mask = graph.get_tensor_by_name(\"output_mrcnn_mask:0\")\n",
    "\n",
    "        #[detections, mrcnn_class, mrcnn_bbox, mrcnn_mask,rois, rpn_class, rpn_bbox]\n",
    "        feed = {input_image:image_resized, input_image_meta:image_meta}\n",
    "        result = sess.run(mrcnn_mask, feed_dict = feed)\n",
    "        print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('python36': conda)",
   "language": "python",
   "name": "python36864bitpython36conda00e070e34b0140f9b8610d8486cbe931"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
